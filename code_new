
######################################## Importing Libraries ####################################################################

from sklearn.model_selection import PredefinedSplit
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import PredefinedSplit
from sklearn.base import TransformerMixin
from sklearn.metrics import roc_auc_score, roc_curve
from sklearn import datasets
from sklearn import metrics
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectFromModel
from sklearn import pipeline
from sklearn.metrics import roc_auc_score, roc_curve
from sklearn import datasets
from sklearn import metrics
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.feature_selection import SelectFromModel
from keras import backend as K
import pandas as pd
import numpy as np
import h5py
import matplotlib.pyplot as plt
import scipy
from PIL import Image
from scipy import ndimage
#from dnn_app_utils_v2 import *
import pandas as pd
%matplotlib inline
from pandas import ExcelWriter
from pandas import ExcelFile
%load_ext autoreload
%autoreload 2
from sklearn.utils import resample
import tensorflow as tf
from tensorflow.python.framework import ops
import openpyxl
import keras
import xlsxwriter
from keras.layers import Dense, Dropout
from keras import optimizers

import pandas as pd
import numpy as np
import h5py
import matplotlib.pyplot as plt
import scipy
from PIL import Image
from scipy import ndimage

import pandas as pd
%matplotlib inline
from pandas import ExcelWriter
from pandas import ExcelFile
%load_ext autoreload
%autoreload 2
from sklearn.utils import resample
import tensorflow as tf
from tensorflow.python.framework import ops
import openpyxl
import keras
import xlsxwriter
from sklearn.preprocessing import Imputer
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

################################## Data Loading#####################################################################

data = pd.read_excel(r'full_data.xlsx')
print(np.shape(data))
################################## Data Cleaning and Normalization#####################################################################

#Showing columns with NAN "CLOUMN TYPE"
#Change the data type of any column if necessary.
data.select_dtypes(exclude=[np.number])

#Now dropping those columns with zero values entirely or which sums to zero
data= data.loc[:, (data != 0).any(axis=0)]

#Now dropping those columns with NAN values entirely 
data=data.dropna(axis=1, how='all')
data=data.dropna(axis=0, how='all')

#Keep track of the columns which are exculded after NAN and column zero sum operation above
print(np.shape(data))

#Seprating out the NAMES of the molecules column and ACTIVITY column because they are not the features to be normalized.
data_input=data.drop(['ACTIVITY', 'NAME'], axis=1)
data_labels= data.ACTIVITY
data_names = data.NAME
print(np.shape(data_input))

#Imputing the missing values with features mean values
fill_NaN = Imputer(missing_values=np.nan, strategy='mean', axis=1)
Imputed_Data_input = pd.DataFrame(fill_NaN.fit_transform(data_input))
print(np.shape(Imputed_Data_input))


#Calculatig the mean and STD of the imputed input data set
Imputed_Data_input_mean=Imputed_Data_input.mean()
Imputed_Data_input_std=Imputed_Data_input.std()

#z-score normalizing the whole input data:
Imputed_Data_input_norm = (Imputed_Data_input - Imputed_Data_input_mean)/Imputed_Data_input_std

#Adding names and labels to the data again
frames = [data_names,data_labels, Imputed_Data_input_norm]
full_data_norm = pd.concat(frames,axis=1)
d
