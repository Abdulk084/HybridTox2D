{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Always keep your Neurons Happy\n",
      "             \n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      " All the necessary Libraries have been loaded\n",
      "             \n",
      " The code after this is for loading your data into train, test and CV. Please make sure the path of correct\n",
      " The data is loaded into train, test and cv\n",
      "             \n",
      "size of train : (9091, 1446)\n",
      "             \n",
      "size of test : (622, 1446)\n",
      "             \n",
      "size of cv : (272, 1446)\n",
      " Now all the test, train and CV will be combined to make it ready for feature scaling \n",
      "             \n",
      "size of train_test_cv: (9985, 1446)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import pipeline\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from keras import backend as K\n",
    "\n",
    "# Libraries import and data preparation\n",
    "\n",
    "print(\" Always keep your Neurons Happy\")\n",
    "print(\"             \")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "#from dnn_app_utils_v2 import *\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sklearn.utils import resample\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import openpyxl\n",
    "import keras\n",
    "import xlsxwriter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "#from dnn_app_utils_v2 import *\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sklearn.utils import resample\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import openpyxl\n",
    "import keras\n",
    "import xlsxwriter\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "print(\" All the necessary Libraries have been loaded\")\n",
    "print(\"             \")\n",
    "print(\" The code after this is for loading your data into train, test and CV. Please make sure the path of correct\")\n",
    "\n",
    "\n",
    "train_orig = pd.read_excel(r'atad5-train.xlsx')\n",
    "test = pd.read_excel(r'atad5-test.xlsx')\n",
    "cv_orig= pd.read_excel(r'atad5-cv.xlsx')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" The data is loaded into train, test and cv\")\n",
    "print(\"             \")\n",
    "\n",
    "\n",
    "\n",
    "#Printing sizes before combining all the three\n",
    "\n",
    "print(\"size of train : \"  + str(np.shape(train_orig)))\n",
    "print(\"             \")\n",
    "print(\"size of test : \"  + str(np.shape(test)))\n",
    "print(\"             \")\n",
    "print(\"size of cv : \"  + str(np.shape(cv_orig)))\n",
    "\n",
    "\n",
    "print(\" Now all the test, train and CV will be combined to make it ready for feature scaling \")\n",
    "print(\"             \")\n",
    "\n",
    "\n",
    "\n",
    "#Combining all the train/test/cv\n",
    "\n",
    "combined = [train_orig , test, cv_orig]\n",
    "ar_fulldata = pd.concat(combined)\n",
    "print(\"size of train_test_cv: \"  + str(np.shape(ar_fulldata)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Now dropping all the rows with NAN values \n",
      "             \n",
      " Now dropping those columns with zero values entirely or which sums to zero \n",
      "             \n",
      " Separating out Activity and Names column \n",
      "             \n",
      " Calculatig the mean and STD of the input data test and train both together \n",
      "             \n",
      " Dividing the whole train and test on its STD anb sabstracting from the mean \n",
      "             \n",
      " Checking iif any columns contain NAN values \n",
      "             \n",
      " Adding names and labels to the full data again \n",
      "             \n"
     ]
    }
   ],
   "source": [
    "#######################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "print(\" Now dropping all the rows with NAN values \")\n",
    "print(\"             \")\n",
    "\n",
    "# Dropping all the rows with \"NAN\" values\n",
    "ar_fulldata=ar_fulldata.dropna()\n",
    "\n",
    "\n",
    "print(\" Now dropping those columns with zero values entirely or which sums to zero \")\n",
    "print(\"             \")\n",
    "\n",
    "# Dropping all the columns with all zero values\n",
    "ar_fulldata = ar_fulldata.loc[:, (ar_fulldata != 0).any(axis=0)]\n",
    "\n",
    "\n",
    "\n",
    "#Separate out the Activity, names and other data\n",
    "print(\" Separating out Activity and Names column \")\n",
    "print(\"             \")\n",
    "\n",
    "ar_fulldata_labels = ar_fulldata.ACTIVITY\n",
    "ar_fulldata_names = ar_fulldata.NAME\n",
    "ar_fulldata_input=ar_fulldata.drop(['ACTIVITY', 'NAME'], axis=1)\n",
    "\n",
    "\n",
    "print(\" Calculatig the mean and STD of the input data test and train both together \")\n",
    "print(\"             \")\n",
    "# Describing Statistics of full data, range, mean and STD \n",
    "ar_fulldata_input_mean=ar_fulldata_input.mean()\n",
    "ar_fulldata_input_std=ar_fulldata_input.std()\n",
    "\n",
    "\n",
    "\n",
    "print(\" Dividing the whole train and test on its STD anb sabstracting from the mean \")\n",
    "print(\"             \")\n",
    "\n",
    "\n",
    "#z-score normalizing the whole input data:\n",
    "ar_fulldata_input_norm = (ar_fulldata_input - ar_fulldata_input_mean)/ar_fulldata_input_std\n",
    "\n",
    "\n",
    "\n",
    "print(\" Checking iif any columns contain NAN values \")\n",
    "print(\"             \")\n",
    "\n",
    "#Checking for the columns with with NAN value.\n",
    "ar_fulldata_input_norm.loc[:, ar_fulldata_input_norm.isnull().any()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" Adding names and labels to the full data again \")\n",
    "print(\"             \")\n",
    "# Adding names and labels\n",
    "frames = [ar_fulldata_names,ar_fulldata_labels, ar_fulldata_input_norm]\n",
    "ar_fulldata_norm = pd.concat(frames,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_train=0\n",
    "end_train=(np.amax(train_orig.index.values)+1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_norm = ar_fulldata_norm.iloc[0:end_train, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Diving into test train and cv again after normalization/scaleerization equally all the three \n",
      "             \n"
     ]
    }
   ],
   "source": [
    "print(\" Diving into test train and cv again after normalization/scaleerization equally all the three \")\n",
    "print(\"             \")\n",
    "\n",
    "\n",
    "start_test=(np.amax(train_orig.index.values)+1)\n",
    "end_test=(np.amax(train_orig.index.values)+1)+(np.amax(test.index.values)+1)\n",
    "\n",
    "\n",
    "\n",
    "test=ar_fulldata_norm.iloc[start_test:end_test, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "start_cv=(np.amax(train_orig.index.values)+1)+(np.amax(test.index.values)+1)\n",
    "end_cv=(np.amax(train_orig.index.values)+1)+(np.amax(test.index.values)+1)+np.amax(cv_orig.index.values)+1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cv_norm=ar_fulldata_norm.iloc[start_cv:end_cv, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " adding cv with train \n",
      "             \n",
      " Now upsampling the train minority and also shuffeling it \n",
      "             \n",
      "Trainig set size after upsampling: (13910, 1270)\n",
      "cross_val set size after upsampling: (3590, 1270)\n",
      " Dividing into train_x , train_y, test_x and test_y and also dropping the Activity and NAME \n",
      "             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:81: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:88: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:101: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    }
   ],
   "source": [
    "print(\" adding cv with train \")\n",
    "print(\"             \")\n",
    "#addind cv with train\n",
    "frames = [train_norm, cv_norm]\n",
    "train_cv_norm = pd.concat(frames)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" Now upsampling the train minority and also shuffeling it \")\n",
    "print(\"             \")\n",
    "\n",
    "\n",
    "# Splitting cv and train before upsampling\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, cross_val = train_test_split(train_cv_norm, test_size=0.20, shuffle=False, random_state=41)\n",
    "\n",
    "\n",
    "train_ones= train['ACTIVITY'].sum()\n",
    "train_zeros=train.shape[0]-train_ones\n",
    "\n",
    "cross_val_ones= cross_val['ACTIVITY'].sum()\n",
    "cross_val_zeros=cross_val.shape[0]-cross_val_ones\n",
    "\n",
    "\n",
    "# Upsampling the training data to balance it and then shuffeling it again.\n",
    "from sklearn.utils import shuffle\n",
    "train_majority = train[train.ACTIVITY==0]\n",
    "train_minority = train[train.ACTIVITY==1]\n",
    "\n",
    "train_minority_upsampled = resample(train_minority, \n",
    "                                 replace=True,     \n",
    "                                 n_samples=train_zeros)    \n",
    "                             \n",
    "train_upsampled = pd.concat([train_majority, train_minority_upsampled])\n",
    "\n",
    "print(\"Trainig set size after upsampling: \"  + str(np.shape(train_upsampled )))\n",
    "\n",
    "train_upsampled=shuffle(train_upsampled)\n",
    "\n",
    "\n",
    "\n",
    "cross_val_majority = cross_val[cross_val.ACTIVITY==0]\n",
    "cross_val_minority = cross_val[cross_val.ACTIVITY==1]\n",
    "\n",
    "cross_val_minority_upsampled = resample(cross_val_minority, \n",
    "                                 replace=True,     \n",
    "                                 n_samples=cross_val_zeros)    \n",
    "                             \n",
    "cross_val_upsampled = pd.concat([cross_val_majority, cross_val_minority_upsampled])\n",
    "\n",
    "print(\"cross_val set size after upsampling: \"  + str(np.shape(cross_val_upsampled )))\n",
    "\n",
    "cross_val_upsampled=shuffle(cross_val_upsampled)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\" Dividing into train_x , train_y, test_x and test_y and also dropping the Activity and NAME \")\n",
    "print(\"             \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_x_upsampled = train_upsampled.drop(['ACTIVITY','NAME'], axis=1)     \n",
    "train_y_upsampled = train_upsampled.ACTIVITY\n",
    "train_y_upsampled =train_y_upsampled .reshape(train_y_upsampled.shape[0],1)\n",
    "train_y_upsampled=pd.DataFrame(train_y_upsampled)\n",
    "\n",
    "\n",
    "\n",
    "cross_val_x_upsampled = cross_val_upsampled.drop(['ACTIVITY','NAME'], axis=1)     \n",
    "cross_val_y_upsampled = cross_val_upsampled.ACTIVITY\n",
    "cross_val_y_upsampled=cross_val_y_upsampled .reshape(cross_val_y_upsampled.shape[0],1)\n",
    "cross_val_y_upsampled=pd.DataFrame(cross_val_y_upsampled)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_x = test.drop(['ACTIVITY','NAME'], axis=1)     \n",
    "test_y = test.ACTIVITY\n",
    "test_y = test_y .reshape(test_y .shape[0],1)\n",
    "test_y=pd.DataFrame(test_y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Writing test set to exel after normalization\n",
    "\n",
    "\n",
    "writer = pd.ExcelWriter('test.xlsx',engine='xlsxwriter')\n",
    "pd.DataFrame(test_x).to_excel(writer,sheet_name='test_x')\n",
    "pd.DataFrame(test_y).to_excel(writer,sheet_name='test_y')\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:37: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11666, 518)\n",
      "518\n",
      "Epoch 1/20\n",
      "11666/11666 [==============================] - 3s - loss: 0.6055 - binary_crossentropy: 0.6055     \n",
      "Epoch 2/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.5404 - binary_crossentropy: 0.5404     \n",
      "Epoch 3/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.5010 - binary_crossentropy: 0.5010     \n",
      "Epoch 4/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.4748 - binary_crossentropy: 0.4748     \n",
      "Epoch 5/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.4541 - binary_crossentropy: 0.4541     \n",
      "Epoch 6/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.4279 - binary_crossentropy: 0.4279     \n",
      "Epoch 7/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.4082 - binary_crossentropy: 0.4082     \n",
      "Epoch 8/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.3915 - binary_crossentropy: 0.3915     \n",
      "Epoch 9/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.3690 - binary_crossentropy: 0.3690     \n",
      "Epoch 10/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.3515 - binary_crossentropy: 0.3515     \n",
      "Epoch 11/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.3374 - binary_crossentropy: 0.3374     \n",
      "Epoch 12/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.3211 - binary_crossentropy: 0.3211     \n",
      "Epoch 13/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.3113 - binary_crossentropy: 0.3113     \n",
      "Epoch 14/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.2963 - binary_crossentropy: 0.2963     \n",
      "Epoch 15/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.2842 - binary_crossentropy: 0.2842     \n",
      "Epoch 16/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.2744 - binary_crossentropy: 0.2744     \n",
      "Epoch 17/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.2609 - binary_crossentropy: 0.2609     \n",
      "Epoch 18/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.2547 - binary_crossentropy: 0.2547     \n",
      "Epoch 19/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.2459 - binary_crossentropy: 0.2459     \n",
      "Epoch 20/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.2330 - binary_crossentropy: 0.2330     \n",
      "(5834, 518)\n",
      "4800/5834 [=======================>......] - ETA: 0s(11666, 518)\n",
      " 8800/11666 [=====================>........] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:37: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11667, 496)\n",
      "496\n",
      "Epoch 1/20\n",
      "11667/11667 [==============================] - 1s - loss: 0.6066 - binary_crossentropy: 0.6066     \n",
      "Epoch 2/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.5439 - binary_crossentropy: 0.5439     \n",
      "Epoch 3/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.5076 - binary_crossentropy: 0.5076     \n",
      "Epoch 4/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4834 - binary_crossentropy: 0.4834     \n",
      "Epoch 5/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4513 - binary_crossentropy: 0.4513     \n",
      "Epoch 6/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4358 - binary_crossentropy: 0.4358     \n",
      "Epoch 7/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4136 - binary_crossentropy: 0.4136     \n",
      "Epoch 8/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3949 - binary_crossentropy: 0.3949     \n",
      "Epoch 9/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3753 - binary_crossentropy: 0.3753     \n",
      "Epoch 10/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3578 - binary_crossentropy: 0.3578     \n",
      "Epoch 11/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3356 - binary_crossentropy: 0.3356     - ETA: 0s - loss: 0.3330 - binary_crossentropy\n",
      "Epoch 12/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3253 - binary_crossentropy: 0.3253     \n",
      "Epoch 13/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3056 - binary_crossentropy: 0.3056     \n",
      "Epoch 14/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2927 - binary_crossentropy: 0.2927     \n",
      "Epoch 15/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2843 - binary_crossentropy: 0.2843     \n",
      "Epoch 16/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2809 - binary_crossentropy: 0.2809     \n",
      "Epoch 17/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2605 - binary_crossentropy: 0.2605     \n",
      "Epoch 18/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2561 - binary_crossentropy: 0.2561     \n",
      "Epoch 19/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2452 - binary_crossentropy: 0.2452     \n",
      "Epoch 20/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2284 - binary_crossentropy: 0.2284     \n",
      "(5833, 496)\n",
      "5200/5833 [=========================>....] - ETA: 0s(11667, 496)\n",
      " 9200/11667 [======================>.......] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:37: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11667, 557)\n",
      "557\n",
      "Epoch 1/20\n",
      "11667/11667 [==============================] - 1s - loss: 0.6268 - binary_crossentropy: 0.6268     \n",
      "Epoch 2/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.5551 - binary_crossentropy: 0.5551     \n",
      "Epoch 3/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.5153 - binary_crossentropy: 0.5153     \n",
      "Epoch 4/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4871 - binary_crossentropy: 0.4871     \n",
      "Epoch 5/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4517 - binary_crossentropy: 0.4517     \n",
      "Epoch 6/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4239 - binary_crossentropy: 0.4239     \n",
      "Epoch 7/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3994 - binary_crossentropy: 0.3994     \n",
      "Epoch 8/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3755 - binary_crossentropy: 0.3755     \n",
      "Epoch 9/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3497 - binary_crossentropy: 0.3497     \n",
      "Epoch 10/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3309 - binary_crossentropy: 0.3309     \n",
      "Epoch 11/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3123 - binary_crossentropy: 0.3123     \n",
      "Epoch 12/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2961 - binary_crossentropy: 0.2961     \n",
      "Epoch 13/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2758 - binary_crossentropy: 0.2758     \n",
      "Epoch 14/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2668 - binary_crossentropy: 0.2668     \n",
      "Epoch 15/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2555 - binary_crossentropy: 0.2555     \n",
      "Epoch 16/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2479 - binary_crossentropy: 0.2479     \n",
      "Epoch 17/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2300 - binary_crossentropy: 0.2300     \n",
      "Epoch 18/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2171 - binary_crossentropy: 0.2171     \n",
      "Epoch 19/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2123 - binary_crossentropy: 0.2123     \n",
      "Epoch 20/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.1998 - binary_crossentropy: 0.1998     \n",
      "(5833, 557)\n",
      "4800/5833 [=======================>......] - ETA: 0s(11667, 557)\n",
      " 8000/11667 [===================>..........] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:37: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11666, 520)\n",
      "520\n",
      "Epoch 1/20\n",
      "11666/11666 [==============================] - 1s - loss: 0.6077 - binary_crossentropy: 0.6077     \n",
      "Epoch 2/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.5434 - binary_crossentropy: 0.5434     \n",
      "Epoch 3/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.5036 - binary_crossentropy: 0.5036     \n",
      "Epoch 4/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.4757 - binary_crossentropy: 0.4757     \n",
      "Epoch 5/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.4549 - binary_crossentropy: 0.4549     \n",
      "Epoch 6/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.4293 - binary_crossentropy: 0.4293     \n",
      "Epoch 7/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.4097 - binary_crossentropy: 0.4097     \n",
      "Epoch 8/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.3932 - binary_crossentropy: 0.3932     \n",
      "Epoch 9/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.3704 - binary_crossentropy: 0.3704     \n",
      "Epoch 10/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.3522 - binary_crossentropy: 0.3522     \n",
      "Epoch 11/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.3382 - binary_crossentropy: 0.3382     \n",
      "Epoch 12/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.3209 - binary_crossentropy: 0.3209     \n",
      "Epoch 13/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.3114 - binary_crossentropy: 0.3114     \n",
      "Epoch 14/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.2958 - binary_crossentropy: 0.2958     \n",
      "Epoch 15/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.2828 - binary_crossentropy: 0.2828     \n",
      "Epoch 16/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.2727 - binary_crossentropy: 0.2727     \n",
      "Epoch 17/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.2585 - binary_crossentropy: 0.2585     \n",
      "Epoch 18/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.2512 - binary_crossentropy: 0.2512     \n",
      "Epoch 19/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.2401 - binary_crossentropy: 0.2401     \n",
      "Epoch 20/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.2239 - binary_crossentropy: 0.2239     \n",
      "(5834, 520)\n",
      "4800/5834 [=======================>......] - ETA: 0s(11666, 520)\n",
      " 8800/11666 [=====================>........] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:37: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11667, 493)\n",
      "493\n",
      "Epoch 1/20\n",
      "11667/11667 [==============================] - 1s - loss: 0.6083 - binary_crossentropy: 0.6083     \n",
      "Epoch 2/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.5451 - binary_crossentropy: 0.5451     \n",
      "Epoch 3/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.5082 - binary_crossentropy: 0.5082     \n",
      "Epoch 4/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4855 - binary_crossentropy: 0.4855     \n",
      "Epoch 5/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4537 - binary_crossentropy: 0.4537     \n",
      "Epoch 6/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4381 - binary_crossentropy: 0.4381     \n",
      "Epoch 7/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4151 - binary_crossentropy: 0.4151     \n",
      "Epoch 8/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3974 - binary_crossentropy: 0.3974     \n",
      "Epoch 9/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3780 - binary_crossentropy: 0.3780     \n",
      "Epoch 10/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3620 - binary_crossentropy: 0.3620     \n",
      "Epoch 11/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3397 - binary_crossentropy: 0.3397     \n",
      "Epoch 12/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3303 - binary_crossentropy: 0.3303     \n",
      "Epoch 13/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3104 - binary_crossentropy: 0.3104     \n",
      "Epoch 14/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2989 - binary_crossentropy: 0.2989     \n",
      "Epoch 15/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2902 - binary_crossentropy: 0.2902     \n",
      "Epoch 16/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2854 - binary_crossentropy: 0.2854     \n",
      "Epoch 17/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2651 - binary_crossentropy: 0.2651     \n",
      "Epoch 18/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2591 - binary_crossentropy: 0.2591     \n",
      "Epoch 19/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2488 - binary_crossentropy: 0.2488     \n",
      "Epoch 20/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2330 - binary_crossentropy: 0.2330     \n",
      "(5833, 493)\n",
      "4800/5833 [=======================>......] - ETA: 0s(11667, 493)\n",
      " 9200/11667 [======================>.......] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:37: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11667, 558)\n",
      "558\n",
      "Epoch 1/20\n",
      "11667/11667 [==============================] - 1s - loss: 0.6283 - binary_crossentropy: 0.6283     \n",
      "Epoch 2/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.5555 - binary_crossentropy: 0.5555     \n",
      "Epoch 3/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.5161 - binary_crossentropy: 0.5161     \n",
      "Epoch 4/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4876 - binary_crossentropy: 0.4876     \n",
      "Epoch 5/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4517 - binary_crossentropy: 0.4517     \n",
      "Epoch 6/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4246 - binary_crossentropy: 0.4246     \n",
      "Epoch 7/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3992 - binary_crossentropy: 0.3992     \n",
      "Epoch 8/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3746 - binary_crossentropy: 0.3746     \n",
      "Epoch 9/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3480 - binary_crossentropy: 0.3480     \n",
      "Epoch 10/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3303 - binary_crossentropy: 0.3303     \n",
      "Epoch 11/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3100 - binary_crossentropy: 0.3100     \n",
      "Epoch 12/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2952 - binary_crossentropy: 0.2952     \n",
      "Epoch 13/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2751 - binary_crossentropy: 0.2751     \n",
      "Epoch 14/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2643 - binary_crossentropy: 0.2643     \n",
      "Epoch 15/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2494 - binary_crossentropy: 0.2494     \n",
      "Epoch 16/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2385 - binary_crossentropy: 0.2385     \n",
      "Epoch 17/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2245 - binary_crossentropy: 0.2245     \n",
      "Epoch 18/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2134 - binary_crossentropy: 0.2134     \n",
      "Epoch 19/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2096 - binary_crossentropy: 0.2096     \n",
      "Epoch 20/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.1979 - binary_crossentropy: 0.1979     \n",
      "(5833, 558)\n",
      "4400/5833 [=====================>........] - ETA: 0s(11667, 558)\n",
      " 8000/11667 [===================>..........] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:37: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11666, 585)\n",
      "585\n",
      "Epoch 1/20\n",
      "11666/11666 [==============================] - 1s - loss: 0.6042 - binary_crossentropy: 0.6042     \n",
      "Epoch 2/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.5379 - binary_crossentropy: 0.5379     \n",
      "Epoch 3/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.4973 - binary_crossentropy: 0.4973     \n",
      "Epoch 4/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.4704 - binary_crossentropy: 0.4704     \n",
      "Epoch 5/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.4451 - binary_crossentropy: 0.4451     \n",
      "Epoch 6/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.4197 - binary_crossentropy: 0.4197     \n",
      "Epoch 7/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.3984 - binary_crossentropy: 0.3984     \n",
      "Epoch 8/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.3800 - binary_crossentropy: 0.3800     \n",
      "Epoch 9/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.3571 - binary_crossentropy: 0.3571     - ETA: 0s - loss: 0.3798 - binary_crossentrop\n",
      "Epoch 10/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.3360 - binary_crossentropy: 0.3360     \n",
      "Epoch 11/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.3211 - binary_crossentropy: 0.3211     \n",
      "Epoch 12/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.3034 - binary_crossentropy: 0.3034     \n",
      "Epoch 13/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.2941 - binary_crossentropy: 0.2941     \n",
      "Epoch 14/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.2776 - binary_crossentropy: 0.2776     \n",
      "Epoch 15/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.2624 - binary_crossentropy: 0.2624     \n",
      "Epoch 16/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.2537 - binary_crossentropy: 0.2537     \n",
      "Epoch 17/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.2364 - binary_crossentropy: 0.2364     \n",
      "Epoch 18/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.2276 - binary_crossentropy: 0.2276     \n",
      "Epoch 19/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.2204 - binary_crossentropy: 0.2204     \n",
      "Epoch 20/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.2090 - binary_crossentropy: 0.2090     \n",
      "(5834, 585)\n",
      "4400/5834 [=====================>........] - ETA: 0s(11666, 585)\n",
      "11600/11666 [============================>.] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:37: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11667, 577)\n",
      "577\n",
      "Epoch 1/20\n",
      "11667/11667 [==============================] - 1s - loss: 0.6080 - binary_crossentropy: 0.6080     \n",
      "Epoch 2/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.5436 - binary_crossentropy: 0.5436     \n",
      "Epoch 3/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.5060 - binary_crossentropy: 0.5060     \n",
      "Epoch 4/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4828 - binary_crossentropy: 0.4828     \n",
      "Epoch 5/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4489 - binary_crossentropy: 0.4489     \n",
      "Epoch 6/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4308 - binary_crossentropy: 0.4308     \n",
      "Epoch 7/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4068 - binary_crossentropy: 0.4068     \n",
      "Epoch 8/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3858 - binary_crossentropy: 0.3858     \n",
      "Epoch 9/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3639 - binary_crossentropy: 0.3639     \n",
      "Epoch 10/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3452 - binary_crossentropy: 0.3452     - ETA: 0s - loss: 0.3473 - binary_crossentropy:\n",
      "Epoch 11/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3232 - binary_crossentropy: 0.3232     \n",
      "Epoch 12/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3104 - binary_crossentropy: 0.3104     \n",
      "Epoch 13/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2889 - binary_crossentropy: 0.2889     \n",
      "Epoch 14/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2773 - binary_crossentropy: 0.2773     \n",
      "Epoch 15/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2665 - binary_crossentropy: 0.2665     \n",
      "Epoch 16/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2598 - binary_crossentropy: 0.2598     \n",
      "Epoch 17/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2405 - binary_crossentropy: 0.2405     \n",
      "Epoch 18/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2343 - binary_crossentropy: 0.2343     \n",
      "Epoch 19/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2242 - binary_crossentropy: 0.2242     \n",
      "Epoch 20/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2102 - binary_crossentropy: 0.2102     \n",
      "(5833, 577)\n",
      "4400/5833 [=====================>........] - ETA: 0s(11667, 577)\n",
      " 8400/11667 [====================>.........] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:37: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11667, 611)\n",
      "611\n",
      "Epoch 1/20\n",
      "11667/11667 [==============================] - 1s - loss: 0.6246 - binary_crossentropy: 0.6246     \n",
      "Epoch 2/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.5530 - binary_crossentropy: 0.5530     \n",
      "Epoch 3/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.5118 - binary_crossentropy: 0.5118     \n",
      "Epoch 4/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4817 - binary_crossentropy: 0.4817     \n",
      "Epoch 5/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4439 - binary_crossentropy: 0.4439     \n",
      "Epoch 6/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4146 - binary_crossentropy: 0.4146     \n",
      "Epoch 7/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3889 - binary_crossentropy: 0.3889     \n",
      "Epoch 8/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3637 - binary_crossentropy: 0.3637     \n",
      "Epoch 9/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3358 - binary_crossentropy: 0.3358     \n",
      "Epoch 10/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3161 - binary_crossentropy: 0.3161     \n",
      "Epoch 11/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2960 - binary_crossentropy: 0.2960     \n",
      "Epoch 12/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2819 - binary_crossentropy: 0.2819     \n",
      "Epoch 13/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2622 - binary_crossentropy: 0.2622     \n",
      "Epoch 14/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2523 - binary_crossentropy: 0.2523     \n",
      "Epoch 15/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2374 - binary_crossentropy: 0.2374     \n",
      "Epoch 16/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2279 - binary_crossentropy: 0.2279     \n",
      "Epoch 17/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2156 - binary_crossentropy: 0.2156     \n",
      "Epoch 18/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2043 - binary_crossentropy: 0.2043     \n",
      "Epoch 19/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2027 - binary_crossentropy: 0.2027     \n",
      "Epoch 20/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.1889 - binary_crossentropy: 0.1889     \n",
      "(5833, 611)\n",
      "4400/5833 [=====================>........] - ETA: 0s(11667, 611)\n",
      "11667/11667 [==============================] - 0s     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:37: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11666, 512)\n",
      "512\n",
      "Epoch 1/20\n",
      "11666/11666 [==============================] - 1s - loss: 0.6054 - binary_crossentropy: 0.6054     \n",
      "Epoch 2/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.5407 - binary_crossentropy: 0.5407     \n",
      "Epoch 3/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.5016 - binary_crossentropy: 0.5016     \n",
      "Epoch 4/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.4745 - binary_crossentropy: 0.4745     \n",
      "Epoch 5/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.4538 - binary_crossentropy: 0.4538     \n",
      "Epoch 6/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.4292 - binary_crossentropy: 0.4292     \n",
      "Epoch 7/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.4098 - binary_crossentropy: 0.4098     \n",
      "Epoch 8/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.3935 - binary_crossentropy: 0.3935     \n",
      "Epoch 9/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.3713 - binary_crossentropy: 0.3713     \n",
      "Epoch 10/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.3532 - binary_crossentropy: 0.3532     \n",
      "Epoch 11/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.3384 - binary_crossentropy: 0.3384     \n",
      "Epoch 12/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.3219 - binary_crossentropy: 0.3219     \n",
      "Epoch 13/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.3120 - binary_crossentropy: 0.3120     \n",
      "Epoch 14/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.2963 - binary_crossentropy: 0.2963     \n",
      "Epoch 15/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.2849 - binary_crossentropy: 0.2849     \n",
      "Epoch 16/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.2742 - binary_crossentropy: 0.2742     \n",
      "Epoch 17/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.2617 - binary_crossentropy: 0.2617     \n",
      "Epoch 18/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.2552 - binary_crossentropy: 0.2552     \n",
      "Epoch 19/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.2454 - binary_crossentropy: 0.2454     \n",
      "Epoch 20/20\n",
      "11666/11666 [==============================] - 0s - loss: 0.2330 - binary_crossentropy: 0.2330     \n",
      "(5834, 512)\n",
      "4400/5834 [=====================>........] - ETA: 0s(11666, 512)\n",
      " 9200/11666 [======================>.......] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:37: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11667, 496)\n",
      "496\n",
      "Epoch 1/20\n",
      "11667/11667 [==============================] - 1s - loss: 0.6079 - binary_crossentropy: 0.6079     \n",
      "Epoch 2/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.5457 - binary_crossentropy: 0.5457     \n",
      "Epoch 3/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.5095 - binary_crossentropy: 0.5095     \n",
      "Epoch 4/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4867 - binary_crossentropy: 0.4867     \n",
      "Epoch 5/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4551 - binary_crossentropy: 0.4551     \n",
      "Epoch 6/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4392 - binary_crossentropy: 0.4392     \n",
      "Epoch 7/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4175 - binary_crossentropy: 0.4175     \n",
      "Epoch 8/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4002 - binary_crossentropy: 0.4002     \n",
      "Epoch 9/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3812 - binary_crossentropy: 0.3812     \n",
      "Epoch 10/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3642 - binary_crossentropy: 0.3642     \n",
      "Epoch 11/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3414 - binary_crossentropy: 0.3414     \n",
      "Epoch 12/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3311 - binary_crossentropy: 0.3311     \n",
      "Epoch 13/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3109 - binary_crossentropy: 0.3109     \n",
      "Epoch 14/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2986 - binary_crossentropy: 0.2986     \n",
      "Epoch 15/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2891 - binary_crossentropy: 0.2891     \n",
      "Epoch 16/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2849 - binary_crossentropy: 0.2849     \n",
      "Epoch 17/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2646 - binary_crossentropy: 0.2646     \n",
      "Epoch 18/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2587 - binary_crossentropy: 0.2587     \n",
      "Epoch 19/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2488 - binary_crossentropy: 0.2488     \n",
      "Epoch 20/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2327 - binary_crossentropy: 0.2327     \n",
      "(5833, 496)\n",
      "4800/5833 [=======================>......] - ETA: 0s(11667, 496)\n",
      " 9200/11667 [======================>.......] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:37: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11667, 561)\n",
      "561\n",
      "Epoch 1/20\n",
      "11667/11667 [==============================] - 1s - loss: 0.6276 - binary_crossentropy: 0.6276     \n",
      "Epoch 2/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.5564 - binary_crossentropy: 0.5564     \n",
      "Epoch 3/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.5166 - binary_crossentropy: 0.5166     \n",
      "Epoch 4/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4884 - binary_crossentropy: 0.4884     \n",
      "Epoch 5/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4523 - binary_crossentropy: 0.4523     \n",
      "Epoch 6/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4258 - binary_crossentropy: 0.4258     \n",
      "Epoch 7/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.4015 - binary_crossentropy: 0.4015     \n",
      "Epoch 8/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3763 - binary_crossentropy: 0.3763     \n",
      "Epoch 9/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3508 - binary_crossentropy: 0.3508     \n",
      "Epoch 10/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3326 - binary_crossentropy: 0.3326     \n",
      "Epoch 11/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.3123 - binary_crossentropy: 0.3123     \n",
      "Epoch 12/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2974 - binary_crossentropy: 0.2974     \n",
      "Epoch 13/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2779 - binary_crossentropy: 0.2779     \n",
      "Epoch 14/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2683 - binary_crossentropy: 0.2683     \n",
      "Epoch 15/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2550 - binary_crossentropy: 0.2550     \n",
      "Epoch 16/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2453 - binary_crossentropy: 0.2453     \n",
      "Epoch 17/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2286 - binary_crossentropy: 0.2286     \n",
      "Epoch 18/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2175 - binary_crossentropy: 0.2175     \n",
      "Epoch 19/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2132 - binary_crossentropy: 0.2132     \n",
      "Epoch 20/20\n",
      "11667/11667 [==============================] - 0s - loss: 0.2011 - binary_crossentropy: 0.2011     \n",
      "(5833, 561)\n",
      "3600/5833 [=================>............] - ETA: 0s(11667, 561)\n",
      "11667/11667 [==============================] - 0s     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:37: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17500, 538)\n",
      "538\n",
      "Epoch 1/20\n",
      "17500/17500 [==============================] - 1s - loss: 0.6027 - binary_crossentropy: 0.6027     \n",
      "Epoch 2/20\n",
      "17500/17500 [==============================] - 0s - loss: 0.5284 - binary_crossentropy: 0.5284     \n",
      "Epoch 3/20\n",
      "17500/17500 [==============================] - 0s - loss: 0.4853 - binary_crossentropy: 0.4853     \n",
      "Epoch 4/20\n",
      "17500/17500 [==============================] - 0s - loss: 0.4463 - binary_crossentropy: 0.4463     \n",
      "Epoch 5/20\n",
      "17500/17500 [==============================] - 0s - loss: 0.4130 - binary_crossentropy: 0.4130     \n",
      "Epoch 6/20\n",
      "17500/17500 [==============================] - 0s - loss: 0.3826 - binary_crossentropy: 0.3826     \n",
      "Epoch 7/20\n",
      "17500/17500 [==============================] - 0s - loss: 0.3543 - binary_crossentropy: 0.3543     \n",
      "Epoch 8/20\n",
      "17500/17500 [==============================] - 0s - loss: 0.3266 - binary_crossentropy: 0.3266     \n",
      "Epoch 9/20\n",
      "17500/17500 [==============================] - 0s - loss: 0.3018 - binary_crossentropy: 0.3018     \n",
      "Epoch 10/20\n",
      "17500/17500 [==============================] - 0s - loss: 0.2776 - binary_crossentropy: 0.2776     \n",
      "Epoch 11/20\n",
      "17500/17500 [==============================] - 0s - loss: 0.2602 - binary_crossentropy: 0.2602     \n",
      "Epoch 12/20\n",
      "17500/17500 [==============================] - 0s - loss: 0.2370 - binary_crossentropy: 0.2370     \n",
      "Epoch 13/20\n",
      "17500/17500 [==============================] - 0s - loss: 0.2213 - binary_crossentropy: 0.2213     \n",
      "Epoch 14/20\n",
      "17500/17500 [==============================] - 0s - loss: 0.2071 - binary_crossentropy: 0.2071     \n",
      "Epoch 15/20\n",
      "17500/17500 [==============================] - 0s - loss: 0.1965 - binary_crossentropy: 0.1965     \n",
      "Epoch 16/20\n",
      "17500/17500 [==============================] - 0s - loss: 0.1919 - binary_crossentropy: 0.1919     \n",
      "Epoch 17/20\n",
      "17500/17500 [==============================] - 0s - loss: 0.1874 - binary_crossentropy: 0.1874     \n",
      "Epoch 18/20\n",
      "17500/17500 [==============================] - 0s - loss: 0.1802 - binary_crossentropy: 0.1802     \n",
      "Epoch 19/20\n",
      "17500/17500 [==============================] - 0s - loss: 0.1727 - binary_crossentropy: 0.1727     \n",
      "Epoch 20/20\n",
      "17500/17500 [==============================] - 0s - loss: 0.1714 - binary_crossentropy: 0.1714     \n",
      "Best: 0.939826 using {'fs__criterion': 'gini', 'fs__n_estimators': 707}\n",
      "0.939826 (0.065030) with: {'fs__criterion': 'gini', 'fs__n_estimators': 707}\n",
      "0.938197 (0.067468) with: {'fs__criterion': 'gini', 'fs__n_estimators': 779}\n",
      "0.934967 (0.075506) with: {'fs__criterion': 'entropy', 'fs__n_estimators': 858}\n",
      "0.938684 (0.066065) with: {'fs__criterion': 'gini', 'fs__n_estimators': 689}\n"
     ]
    }
   ],
   "source": [
    "# Optimizing the tree paramters with 3 cross CV validation\n",
    "\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "session = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "frames11 = [train_x_upsampled, cross_val_x_upsampled]\n",
    "train_cv_x = pd.concat(frames11)\n",
    "\n",
    "frames22 = [train_y_upsampled, cross_val_y_upsampled]\n",
    "train_cv_y = pd.concat(frames22)\n",
    "from scipy.stats import randint as sp_randint\n",
    "xx=0\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "class fs(TransformerMixin, BaseEstimator):\n",
    "\n",
    "    def __init__(self, n_estimators=300, criterion='gini'):\n",
    "        self.ss=None\n",
    "        self.n_estimators = n_estimators\n",
    "        self.x_new = None\n",
    "        self.criterion=criterion\n",
    "\n",
    "        \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        m = ExtraTreesClassifier(self.n_estimators,self.criterion, random_state=0)\n",
    "        m.fit(X,y)\n",
    "        self.ss = SelectFromModel(m, prefit=True)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        self.x_new=self.ss.transform(X)\n",
    "        print(np.shape(self.x_new))\n",
    "        global xx\n",
    "        xx=self.x_new.shape[1]\n",
    "        \n",
    "        \n",
    "        \n",
    "        return self.x_new\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def create_model(dropout_rate=0.7, activation='sigmoid'):\n",
    "    print(xx)\n",
    "\n",
    "\n",
    "    n_x_new=xx\n",
    "    np.random.seed(6000)\n",
    "    model_new = Sequential()\n",
    "    model_new.add(Dense(xx+500,input_dim=xx ,kernel_initializer='glorot_uniform', activation='sigmoid'))\n",
    "    model_new.add(Dense(10, kernel_initializer='glorot_uniform', activation='sigmoid'))\n",
    "    model_new.add(Dropout(dropout_rate))\n",
    "    model_new.add(Dense(1,kernel_initializer='glorot_uniform', activation='sigmoid'))\n",
    "    #optimizer = keras.optimizers.Adam(lr=learn_rate)\n",
    "    model_new.compile(loss='binary_crossentropy',optimizer='adam', metrics=['binary_crossentropy'])\n",
    "\n",
    "    return model_new\n",
    "\n",
    "\n",
    "\n",
    "clf=KerasClassifier(build_fn=create_model, epochs=20, batch_size=400, verbose=1)\n",
    "\n",
    "model = Pipeline([('fs', fs()),('clf', clf)])\n",
    "\n",
    "         \n",
    "param_dist = {'fs__n_estimators': sp_randint (300, 1000),\n",
    "              'fs__criterion':  ('gini', 'entropy')\n",
    "              \n",
    "}\n",
    "        \n",
    "n_iter_search = 4\n",
    "\n",
    "grid = RandomizedSearchCV(estimator=model,param_distributions=param_dist,scoring='roc_auc',error_score=0,  n_iter=n_iter_search, n_jobs=1)\n",
    "grid_result = grid.fit(train_cv_x, train_cv_y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Now is the turn to select important features basesd on tree search\n",
      "             \n",
      " Combining train_upsampled and test for prepairing it for important feature selection\n",
      "             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:40: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Getting features names \n",
      "  \n",
      " adding names and important feature values \n",
      "  \n",
      " dividing the imporrtant features into train and test \n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Selecting the new features based on the tree paramters optimization\n",
    "\n",
    "\n",
    "\n",
    "print(\" Now is the turn to select important features basesd on tree search\")\n",
    "print(\"             \")\n",
    "\n",
    "\n",
    "print(\" Combining train_upsampled and test for prepairing it for important feature selection\")\n",
    "print(\"             \")\n",
    "frames11 = [train_x_upsampled, cross_val_x_upsampled]\n",
    "train_cv_x = pd.concat(frames11)\n",
    "\n",
    "frames22 = [train_y_upsampled, cross_val_y_upsampled]\n",
    "train_cv_y = pd.concat(frames22)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Code for important feature selection\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "#grid_result.best_params_[\"fs__n_estimators\"]\n",
    "\n",
    "    \n",
    "m = ExtraTreesClassifier(n_estimators=1000)\n",
    "#m = ExtraTreesClassifier(150)\n",
    "\n",
    "\n",
    "m.fit(train_cv_x,train_cv_y)\n",
    "\n",
    "\n",
    "sel = SelectFromModel(m,threshold='1.1*mean', prefit=True)\n",
    "\n",
    "print(\" Getting features names \")\n",
    "print(\"  \")\n",
    "feature_idx = sel.get_support()\n",
    "feature_name = train_cv_x.columns[feature_idx]\n",
    "feature_name =pd.DataFrame(feature_name )\n",
    "\n",
    "X_new = sel.transform(train_cv_x)\n",
    "X_new =pd.DataFrame(X_new)\n",
    "\n",
    "\n",
    "print(\" adding names and important feature values \")\n",
    "print(\"  \")\n",
    "X_new.columns = feature_name\n",
    "\n",
    "\n",
    "\n",
    "print(\" dividing the imporrtant features into train and test \")\n",
    "print(\"  \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "writer = pd.ExcelWriter('feature_name.xlsx',engine='xlsxwriter')\n",
    "pd.DataFrame(feature_name).to_excel(writer,sheet_name='feature_name')\n",
    "\n",
    "\n",
    "writer.save()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xls = pd.ExcelFile(\"test.xlsx\")\n",
    "test_x = pd.read_excel(xls, 'test_x')\n",
    "test_y = pd.read_excel(xls, 'test_y') \n",
    "\n",
    " \n",
    "feature_name=feature_name.T\n",
    "feature_name.columns = feature_name.iloc[0]\n",
    "feature_name.reindex(feature_name.index.drop(0))\n",
    "train_selected_x=train_cv_x[train_cv_x.columns.intersection(feature_name.columns)]\n",
    "test_selected_x=test_x[test_x.columns.intersection(feature_name.columns)]\n",
    "\n",
    "\n",
    "train_selected_x=train_selected_x.as_matrix()\n",
    "test_selected_x=test_selected_x.as_matrix()\n",
    "\n",
    "train_selected_y=train_cv_y.as_matrix()\n",
    "\n",
    "test_selected_y=test_y.as_matrix()\n",
    "\n",
    "\n",
    "\n",
    "writer = pd.ExcelWriter('test_selected.xlsx',engine='xlsxwriter')\n",
    "pd.DataFrame(test_selected_x).to_excel(writer,sheet_name='test_selected_x')\n",
    "pd.DataFrame(test_selected_y).to_excel(writer,sheet_name='test_selected_y')\n",
    "\n",
    "writer.save()\n",
    "########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390\n",
      "Epoch 1/20\n",
      "17500/17500 [==============================] - 3s 157us/step - loss: 0.6159 - binary_crossentropy: 0.6159\n",
      "Epoch 2/20\n",
      "17500/17500 [==============================] - 2s 122us/step - loss: 0.4631 - binary_crossentropy: 0.4631\n",
      "Epoch 3/20\n",
      "17500/17500 [==============================] - 2s 140us/step - loss: 0.3824 - binary_crossentropy: 0.3824\n",
      "Epoch 4/20\n",
      "17500/17500 [==============================] - 3s 143us/step - loss: 0.3302 - binary_crossentropy: 0.3302\n",
      "Epoch 5/20\n",
      "17500/17500 [==============================] - 2s 139us/step - loss: 0.2910 - binary_crossentropy: 0.2910\n",
      "Epoch 6/20\n",
      "17500/17500 [==============================] - 2s 138us/step - loss: 0.2573 - binary_crossentropy: 0.2573\n",
      "Epoch 7/20\n",
      "17500/17500 [==============================] - 2s 124us/step - loss: 0.2303 - binary_crossentropy: 0.2303\n",
      "Epoch 8/20\n",
      "17500/17500 [==============================] - 2s 122us/step - loss: 0.2078 - binary_crossentropy: 0.2078\n",
      "Epoch 9/20\n",
      "17500/17500 [==============================] - 2s 129us/step - loss: 0.1918 - binary_crossentropy: 0.1918\n",
      "Epoch 10/20\n",
      "17500/17500 [==============================] - 3s 160us/step - loss: 0.1735 - binary_crossentropy: 0.1735\n",
      "Epoch 11/20\n",
      "17500/17500 [==============================] - 2s 122us/step - loss: 0.1613 - binary_crossentropy: 0.1613\n",
      "Epoch 12/20\n",
      "17500/17500 [==============================] - 2s 119us/step - loss: 0.1488 - binary_crossentropy: 0.1488\n",
      "Epoch 13/20\n",
      "17500/17500 [==============================] - 2s 125us/step - loss: 0.1373 - binary_crossentropy: 0.1373\n",
      "Epoch 14/20\n",
      "17500/17500 [==============================] - 2s 118us/step - loss: 0.1304 - binary_crossentropy: 0.1304\n",
      "Epoch 15/20\n",
      "17500/17500 [==============================] - 2s 118us/step - loss: 0.1234 - binary_crossentropy: 0.1234\n",
      "Epoch 16/20\n",
      "17500/17500 [==============================] - 2s 119us/step - loss: 0.1157 - binary_crossentropy: 0.1157\n",
      "Epoch 17/20\n",
      "17500/17500 [==============================] - 2s 118us/step - loss: 0.1094 - binary_crossentropy: 0.1094\n",
      "Epoch 18/20\n",
      "17500/17500 [==============================] - 2s 118us/step - loss: 0.1035 - binary_crossentropy: 0.1035\n",
      "Epoch 19/20\n",
      "17500/17500 [==============================] - 2s 118us/step - loss: 0.0990 - binary_crossentropy: 0.0990\n",
      "Epoch 20/20\n",
      "17500/17500 [==============================] - 2s 130us/step - loss: 0.0962 - binary_crossentropy: 0.0962\n",
      "AUROC_test: 0.819214608082\n",
      "  \n",
      "Saved model to disk\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#drop_best\n",
    "\n",
    "print(train_selected_x.shape[1])\n",
    "\n",
    "model_new_1 = Sequential()\n",
    "#n_x_new=train_selected_x.shape[1]\n",
    "n_x_new=train_selected_x.shape[1]\n",
    "model_new_1.add(Dense(n_x_new, input_dim=n_x_new, kernel_initializer ='he_normal', activation='relu'))\n",
    "\n",
    "\n",
    "model_new_1.add(Dense(10, kernel_initializer='he_normal', activation='relu'))\n",
    "model_new_1.add(Dropout(0.1))\n",
    "\n",
    "#dp=0.4\n",
    "#epochs=10\n",
    "#batch_size=3000\n",
    "#input_neueon=1000\n",
    "#ini=he_normal\n",
    "model_new_1.add(Dense(1, kernel_initializer='he_normal', activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_new_1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_crossentropy'])\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "model_new_1.fit(train_selected_x, train_selected_y, epochs=20, batch_size=4096)\n",
    "\n",
    "pred_test_1 = model_new_1.predict(test_selected_x)\n",
    "auc_test_1 = roc_auc_score(test_selected_y, pred_test_1)\n",
    "print (\"AUROC_test: \" + str(auc_test_1))\n",
    "\n",
    "print(\"  \") \n",
    "model_json = model_new_1.to_json()\n",
    "with open(\"1_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_new_1.save_weights(\"1_model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "print(\"  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390\n",
      "Epoch 1/20\n",
      "17500/17500 [==============================] - 3s 160us/step - loss: 0.6159 - binary_crossentropy: 0.6159\n",
      "Epoch 2/20\n",
      "17500/17500 [==============================] - 2s 141us/step - loss: 0.4635 - binary_crossentropy: 0.4635\n",
      "Epoch 3/20\n",
      "17500/17500 [==============================] - 3s 146us/step - loss: 0.3828 - binary_crossentropy: 0.3828\n",
      "Epoch 4/20\n",
      "17500/17500 [==============================] - 2s 129us/step - loss: 0.3306 - binary_crossentropy: 0.3306\n",
      "Epoch 5/20\n",
      "17500/17500 [==============================] - 2s 119us/step - loss: 0.2911 - binary_crossentropy: 0.2911\n",
      "Epoch 6/20\n",
      "17500/17500 [==============================] - 2s 119us/step - loss: 0.2572 - binary_crossentropy: 0.2572\n",
      "Epoch 7/20\n",
      "17500/17500 [==============================] - 2s 118us/step - loss: 0.2301 - binary_crossentropy: 0.2301\n",
      "Epoch 8/20\n",
      "17500/17500 [==============================] - 2s 118us/step - loss: 0.2077 - binary_crossentropy: 0.2077\n",
      "Epoch 9/20\n",
      "17500/17500 [==============================] - 2s 119us/step - loss: 0.1917 - binary_crossentropy: 0.1917\n",
      "Epoch 10/20\n",
      "17500/17500 [==============================] - 2s 119us/step - loss: 0.1739 - binary_crossentropy: 0.1739\n",
      "Epoch 11/20\n",
      "17500/17500 [==============================] - 2s 120us/step - loss: 0.1615 - binary_crossentropy: 0.1615\n",
      "Epoch 12/20\n",
      "17500/17500 [==============================] - 2s 118us/step - loss: 0.1489 - binary_crossentropy: 0.1489\n",
      "Epoch 13/20\n",
      "17500/17500 [==============================] - 2s 118us/step - loss: 0.1374 - binary_crossentropy: 0.1374\n",
      "Epoch 14/20\n",
      "17500/17500 [==============================] - 2s 118us/step - loss: 0.1307 - binary_crossentropy: 0.1307\n",
      "Epoch 15/20\n",
      "17500/17500 [==============================] - 2s 119us/step - loss: 0.1236 - binary_crossentropy: 0.1236\n",
      "Epoch 16/20\n",
      "17500/17500 [==============================] - 2s 118us/step - loss: 0.1162 - binary_crossentropy: 0.1162\n",
      "Epoch 17/20\n",
      "17500/17500 [==============================] - 2s 118us/step - loss: 0.1098 - binary_crossentropy: 0.1098\n",
      "Epoch 18/20\n",
      "17500/17500 [==============================] - 2s 119us/step - loss: 0.1046 - binary_crossentropy: 0.1046\n",
      "Epoch 19/20\n",
      "17500/17500 [==============================] - 2s 118us/step - loss: 0.1000 - binary_crossentropy: 0.1000\n",
      "Epoch 20/20\n",
      "17500/17500 [==============================] - 2s 118us/step - loss: 0.0961 - binary_crossentropy: 0.0961\n",
      "AUROC_test: 0.82030398921\n",
      "  \n",
      "Saved model to disk\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#drop_best\n",
    "\n",
    "print(train_selected_x.shape[1])\n",
    "\n",
    "model_new_2 = Sequential()\n",
    "#n_x_new=train_selected_x.shape[1]\n",
    "n_x_new=train_selected_x.shape[1]\n",
    "model_new_2.add(Dense(n_x_new, input_dim=n_x_new, kernel_initializer ='he_normal', activation='relu'))\n",
    "\n",
    "\n",
    "model_new_2.add(Dense(10, kernel_initializer='he_normal', activation='relu'))\n",
    "model_new_2.add(Dropout(0.1))\n",
    "\n",
    "#dp=0.4\n",
    "#epochs=10\n",
    "#batch_size=3000\n",
    "#input_neueon=1000\n",
    "#ini=he_normal\n",
    "model_new_2.add(Dense(1, kernel_initializer='he_normal', activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_new_2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_crossentropy'])\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "model_new_2.fit(train_selected_x, train_selected_y, epochs=20, batch_size=4096)\n",
    "\n",
    "\n",
    "pred_test_2 = model_new_2.predict(test_selected_x)\n",
    "auc_test_2 = roc_auc_score(test_selected_y, pred_test_2)\n",
    "print (\"AUROC_test: \" + str(auc_test_2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"  \") \n",
    "model_json = model_new_2.to_json()\n",
    "with open(\"2_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_new_2.save_weights(\"2_model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "print(\"  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC_test: 0.819785236292\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#pred_train = model_new_1.predict(train_selected_x)\n",
    "pred_test_1 = model_new_1.predict(test_selected_x)\n",
    "pred_test_2 = model_new_2.predict(test_selected_x)\n",
    "\n",
    "#auc_train = roc_auc_score(train_selected_y, pred_train)\n",
    "\n",
    "#### Averaging the ouput \n",
    "pred_test=(pred_test_1+pred_test_2)/2\n",
    "\n",
    "\n",
    "auc_test = roc_auc_score(test_selected_y, pred_test)\n",
    "\n",
    "\n",
    "print (\"AUROC_test: \" + str(auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390\n",
      "Epoch 1/20\n",
      "17500/17500 [==============================] - 3s 194us/step - loss: 0.6159 - binary_crossentropy: 0.6159\n",
      "Epoch 2/20\n",
      "17500/17500 [==============================] - 2s 136us/step - loss: 0.4632 - binary_crossentropy: 0.4632\n",
      "Epoch 3/20\n",
      "17500/17500 [==============================] - 2s 141us/step - loss: 0.3825 - binary_crossentropy: 0.3825\n",
      "Epoch 4/20\n",
      "17500/17500 [==============================] - 2s 127us/step - loss: 0.3304 - binary_crossentropy: 0.3304\n",
      "Epoch 5/20\n",
      "17500/17500 [==============================] - 2s 119us/step - loss: 0.2911 - binary_crossentropy: 0.2911\n",
      "Epoch 6/20\n",
      "17500/17500 [==============================] - 2s 132us/step - loss: 0.2574 - binary_crossentropy: 0.2574\n",
      "Epoch 7/20\n",
      "17500/17500 [==============================] - 2s 132us/step - loss: 0.2306 - binary_crossentropy: 0.2306\n",
      "Epoch 8/20\n",
      "17500/17500 [==============================] - 2s 119us/step - loss: 0.2080 - binary_crossentropy: 0.2080\n",
      "Epoch 9/20\n",
      "17500/17500 [==============================] - 2s 120us/step - loss: 0.1918 - binary_crossentropy: 0.1918\n",
      "Epoch 10/20\n",
      "17500/17500 [==============================] - 2s 119us/step - loss: 0.1738 - binary_crossentropy: 0.1738\n",
      "Epoch 11/20\n",
      "17500/17500 [==============================] - 2s 118us/step - loss: 0.1616 - binary_crossentropy: 0.1616\n",
      "Epoch 12/20\n",
      "17500/17500 [==============================] - 2s 119us/step - loss: 0.1489 - binary_crossentropy: 0.1489\n",
      "Epoch 13/20\n",
      "17500/17500 [==============================] - 2s 118us/step - loss: 0.1374 - binary_crossentropy: 0.1374\n",
      "Epoch 14/20\n",
      "17500/17500 [==============================] - 2s 120us/step - loss: 0.1307 - binary_crossentropy: 0.1307\n",
      "Epoch 15/20\n",
      "17500/17500 [==============================] - 2s 120us/step - loss: 0.1235 - binary_crossentropy: 0.1235\n",
      "Epoch 16/20\n",
      "17500/17500 [==============================] - 2s 124us/step - loss: 0.1158 - binary_crossentropy: 0.1158\n",
      "Epoch 17/20\n",
      "17500/17500 [==============================] - 2s 124us/step - loss: 0.1095 - binary_crossentropy: 0.1095\n",
      "Epoch 18/20\n",
      "17500/17500 [==============================] - 2s 120us/step - loss: 0.1034 - binary_crossentropy: 0.1034\n",
      "Epoch 19/20\n",
      "17500/17500 [==============================] - 2s 118us/step - loss: 0.0989 - binary_crossentropy: 0.0989\n",
      "Epoch 20/20\n",
      "17500/17500 [==============================] - 2s 118us/step - loss: 0.0959 - binary_crossentropy: 0.0959\n",
      "AUROC_test: 0.820407739794\n",
      "  \n",
      "Saved model to disk\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#drop_best\n",
    "\n",
    "print(train_selected_x.shape[1])\n",
    "\n",
    "model_new_3 = Sequential()\n",
    "#n_x_new=train_selected_x.shape[1]\n",
    "n_x_new=train_selected_x.shape[1]\n",
    "model_new_3.add(Dense(n_x_new, input_dim=n_x_new, kernel_initializer ='he_normal', activation='relu'))\n",
    "\n",
    "\n",
    "model_new_3.add(Dense(10, kernel_initializer='he_normal', activation='relu'))\n",
    "model_new_3.add(Dropout(0.1))\n",
    "\n",
    "#dp=0.4\n",
    "#epochs=10\n",
    "#batch_size=3000\n",
    "#input_neueon=1000\n",
    "#ini=he_normal\n",
    "model_new_3.add(Dense(1, kernel_initializer='he_normal', activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_new_3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_crossentropy'])\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "model_new_3.fit(train_selected_x, train_selected_y, epochs=20, batch_size=4096)\n",
    "\n",
    "pred_test_3 = model_new_3.predict(test_selected_x)\n",
    "auc_test_3 = roc_auc_score(test_selected_y, pred_test_3)\n",
    "print (\"AUROC_test: \" + str(auc_test_3))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"  \") \n",
    "model_json = model_new_3.to_json()\n",
    "with open(\"3_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_new_3.save_weights(\"3_model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "print(\"  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC_test: 0.819940862167\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#pred_train = model_new_1.predict(train_selected_x)\n",
    "pred_test_1 = model_new_1.predict(test_selected_x)\n",
    "pred_test_2 = model_new_2.predict(test_selected_x)\n",
    "pred_test_3 = model_new_3.predict(test_selected_x)\n",
    "\n",
    "#auc_train = roc_auc_score(train_selected_y, pred_train)\n",
    "\n",
    "#### Averaging the ouput \n",
    "pred_test=(pred_test_1+pred_test_2+pred_test_3)/3\n",
    "\n",
    "\n",
    "auc_test = roc_auc_score(test_selected_y, pred_test)\n",
    "\n",
    "\n",
    "print (\"AUROC_test: \" + str(auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390\n",
      "Epoch 1/20\n",
      "17500/17500 [==============================] - 3s 167us/step - loss: 0.6159 - binary_crossentropy: 0.6159\n",
      "Epoch 2/20\n",
      "17500/17500 [==============================] - 3s 143us/step - loss: 0.4631 - binary_crossentropy: 0.4631\n",
      "Epoch 3/20\n",
      "17500/17500 [==============================] - 3s 149us/step - loss: 0.3824 - binary_crossentropy: 0.3824\n",
      "Epoch 4/20\n",
      "17500/17500 [==============================] - 3s 146us/step - loss: 0.3302 - binary_crossentropy: 0.3302\n",
      "Epoch 5/20\n",
      "17500/17500 [==============================] - 2s 123us/step - loss: 0.2908 - binary_crossentropy: 0.2908\n",
      "Epoch 6/20\n",
      "17500/17500 [==============================] - 2s 119us/step - loss: 0.2570 - binary_crossentropy: 0.2570\n",
      "Epoch 7/20\n",
      "17500/17500 [==============================] - 2s 122us/step - loss: 0.2297 - binary_crossentropy: 0.2297\n",
      "Epoch 8/20\n",
      "17500/17500 [==============================] - 2s 120us/step - loss: 0.2075 - binary_crossentropy: 0.2075\n",
      "Epoch 9/20\n",
      "17500/17500 [==============================] - 2s 120us/step - loss: 0.1914 - binary_crossentropy: 0.1914\n",
      "Epoch 10/20\n",
      "17500/17500 [==============================] - 2s 122us/step - loss: 0.1733 - binary_crossentropy: 0.1733\n",
      "Epoch 11/20\n",
      "17500/17500 [==============================] - 2s 124us/step - loss: 0.1610 - binary_crossentropy: 0.1610\n",
      "Epoch 12/20\n",
      "17500/17500 [==============================] - 2s 120us/step - loss: 0.1484 - binary_crossentropy: 0.1484\n",
      "Epoch 13/20\n",
      "17500/17500 [==============================] - 2s 118us/step - loss: 0.1370 - binary_crossentropy: 0.1370\n",
      "Epoch 14/20\n",
      "17500/17500 [==============================] - 2s 119us/step - loss: 0.1304 - binary_crossentropy: 0.1304\n",
      "Epoch 15/20\n",
      "17500/17500 [==============================] - 2s 123us/step - loss: 0.1235 - binary_crossentropy: 0.1235\n",
      "Epoch 16/20\n",
      "17500/17500 [==============================] - 2s 125us/step - loss: 0.1161 - binary_crossentropy: 0.1161\n",
      "Epoch 17/20\n",
      "17500/17500 [==============================] - 2s 124us/step - loss: 0.1098 - binary_crossentropy: 0.1098\n",
      "Epoch 18/20\n",
      "17500/17500 [==============================] - 2s 128us/step - loss: 0.1042 - binary_crossentropy: 0.1042\n",
      "Epoch 19/20\n",
      "17500/17500 [==============================] - 2s 126us/step - loss: 0.0993 - binary_crossentropy: 0.0993\n",
      "Epoch 20/20\n",
      "17500/17500 [==============================] - 2s 125us/step - loss: 0.0958 - binary_crossentropy: 0.0958\n",
      "AUROC_test: 0.819422109249\n",
      "  \n",
      "Saved model to disk\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#drop_best\n",
    "\n",
    "print(train_selected_x.shape[1])\n",
    "\n",
    "model_new_4 = Sequential()\n",
    "#n_x_new=train_selected_x.shape[1]\n",
    "n_x_new=train_selected_x.shape[1]\n",
    "model_new_4.add(Dense(n_x_new, input_dim=n_x_new, kernel_initializer ='he_normal', activation='relu'))\n",
    "\n",
    "\n",
    "model_new_4.add(Dense(10, kernel_initializer='he_normal', activation='relu'))\n",
    "model_new_4.add(Dropout(0.1))\n",
    "\n",
    "#dp=0.4\n",
    "#epochs=10\n",
    "#batch_size=3000\n",
    "#input_neueon=1000\n",
    "#ini=he_normal\n",
    "model_new_4.add(Dense(1, kernel_initializer='he_normal', activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_new_4.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_crossentropy'])\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "model_new_4.fit(train_selected_x, train_selected_y, epochs=20, batch_size=4096)\n",
    "\n",
    "pred_test_4 = model_new_4.predict(test_selected_x)\n",
    "auc_test_4 = roc_auc_score(test_selected_y, pred_test_4)\n",
    "print (\"AUROC_test: \" + str(auc_test_4))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"  \") \n",
    "model_json = model_new_4.to_json()\n",
    "with open(\"4_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_new_4.save_weights(\"4_model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "print(\"  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC_test: 0.819785236292\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#pred_train = model_new_1.predict(train_selected_x)\n",
    "pred_test_1 = model_new_1.predict(test_selected_x)\n",
    "pred_test_2 = model_new_2.predict(test_selected_x)\n",
    "pred_test_3 = model_new_3.predict(test_selected_x)\n",
    "pred_test_4 = model_new_4.predict(test_selected_x)\n",
    "#auc_train = roc_auc_score(train_selected_y, pred_train)\n",
    "\n",
    "#### Averaging the ouput \n",
    "pred_test=(pred_test_1+pred_test_2+pred_test_3+pred_test_4)/4\n",
    "\n",
    "\n",
    "auc_test = roc_auc_score(test_selected_y, pred_test)\n",
    "\n",
    "\n",
    "print (\"AUROC_test: \" + str(auc_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
